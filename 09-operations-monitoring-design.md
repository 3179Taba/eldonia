# 09. é‹ç”¨ãƒ»ç›£è¦–è¨­è¨ˆ

## 9.1 é‹ç”¨æ–¹é‡æ¦‚è¦

### 9.1.1 é‹ç”¨ç†å¿µ
- **24/7å¯ç”¨æ€§**: 99.9%ä»¥ä¸Šã®ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ ç¶­æŒ
- **ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç›£è¦–**: å•é¡Œã®æ—©æœŸç™ºè¦‹ãƒ»äºˆé˜²çš„å¯¾å¿œ
- **è‡ªå‹•åŒ–å„ªå…ˆ**: é‹ç”¨ä½œæ¥­ã®è‡ªå‹•åŒ–ã«ã‚ˆã‚‹äººçš„ãƒŸã‚¹å‰Šæ¸›
- **è¿…é€Ÿãªå¾©æ—§**: éšœå®³ç™ºç”Ÿæ™‚ã®è¿…é€Ÿãªå¯¾å¿œãƒ»å¾©æ—§
- **ç¶™ç¶šçš„æ”¹å–„**: é‹ç”¨ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ããƒ—ãƒ­ã‚»ã‚¹æ”¹å–„

### 9.1.2 é‹ç”¨ä½“åˆ¶
- **1æ¬¡å¯¾å¿œ**: é–‹ç™ºãƒãƒ¼ãƒ ï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰
- **2æ¬¡å¯¾å¿œ**: ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ ï¼ˆ4æ™‚é–“ä»¥å†…ï¼‰
- **3æ¬¡å¯¾å¿œ**: å¤–éƒ¨ãƒ™ãƒ³ãƒ€ãƒ¼ï¼ˆ8æ™‚é–“ä»¥å†…ï¼‰
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: é‡å¤§éšœå®³æ™‚ã®çµŒå–¶å±¤ã¸ã®å ±å‘Š

## 9.2 ç›£è¦–æˆ¦ç•¥

### 9.2.1 ç›£è¦–å¯¾è±¡
```
ç›£è¦–ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹æˆ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application Layer (ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤) â”‚
â”‚ â”œâ”€â”€ API Response Time               â”‚
â”‚ â”œâ”€â”€ Error Rate                      â”‚
â”‚ â”œâ”€â”€ Throughput                      â”‚
â”‚ â””â”€â”€ Business Metrics                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Infrastructure Layer (ã‚¤ãƒ³ãƒ•ãƒ©å±¤)    â”‚
â”‚ â”œâ”€â”€ CPU, Memory, Disk              â”‚
â”‚ â”œâ”€â”€ Network I/O                     â”‚
â”‚ â”œâ”€â”€ Container Health               â”‚
â”‚ â””â”€â”€ Service Discovery              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Database Layer (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¤)      â”‚
â”‚ â”œâ”€â”€ Query Performance              â”‚
â”‚ â”œâ”€â”€ Connection Pool                â”‚
â”‚ â”œâ”€â”€ Replication Lag                â”‚
â”‚ â””â”€â”€ Storage Usage                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ External Services (å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹å±¤)   â”‚
â”‚ â”œâ”€â”€ AWS Service Health             â”‚
â”‚ â”œâ”€â”€ Third-party API Status         â”‚
â”‚ â”œâ”€â”€ CDN Performance                â”‚
â”‚ â””â”€â”€ Payment Gateway                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2.2 ç›£è¦–ãƒ„ãƒ¼ãƒ«æ§‹æˆ
```yaml
# monitoring-stack.yml
version: '3.8'
services:
  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  # ãƒ­ã‚°åé›†
  fluentd:
    image: fluent/fluentd:v1.16-1
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./logs:/var/log
    ports:
      - "24224:24224"
      - "24224:24224/udp"

  # å¯è¦–åŒ–
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

  # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager

  # åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268:14268"

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:
```

## 9.3 ãƒ­ã‚°ç®¡ç†è¨­è¨ˆ

### 9.3.1 ãƒ­ã‚°æ§‹é€ 
```typescript
// backend/src/utils/logger.ts
import winston from 'winston';
import { ElasticsearchTransport } from 'winston-elasticsearch';

export interface LogEntry {
  timestamp: string;
  level: 'error' | 'warn' | 'info' | 'debug';
  service: string;
  component: string;
  operation: string;
  userId?: string;
  sessionId?: string;
  requestId?: string;
  ipAddress?: string;
  userAgent?: string;
  message: string;
  metadata?: Record<string, any>;
  error?: {
    name: string;
    message: string;
    stack?: string;
    code?: string;
  };
  performance?: {
    duration: number;
    memoryUsage: number;
    cpuUsage: number;
  };
}

export class Logger {
  private logger: winston.Logger;

  constructor(service: string) {
    this.logger = winston.createLogger({
      level: process.env.LOG_LEVEL || 'info',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.errors({ stack: true }),
        winston.format.json()
      ),
      defaultMeta: { service },
      transports: [
        // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        new winston.transports.Console({
          format: winston.format.combine(
            winston.format.colorize(),
            winston.format.simple()
          )
        }),
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        new winston.transports.File({
          filename: 'logs/error.log',
          level: 'error',
          maxsize: 5242880, // 5MB
          maxFiles: 5
        }),
        
        new winston.transports.File({
          filename: 'logs/combined.log',
          maxsize: 5242880, // 5MB
          maxFiles: 5
        }),
        
        // Elasticsearchå‡ºåŠ›
        new ElasticsearchTransport({
          level: 'info',
          clientOpts: {
            node: process.env.ELASTICSEARCH_URL || 'http://localhost:9200',
            index: `eldonia-logs-${service}`,
            auth: {
              username: process.env.ELASTICSEARCH_USER,
              password: process.env.ELASTICSEARCH_PASSWORD
            }
          },
          indexPrefix: 'eldonia-logs',
          ensureMappingTemplate: true,
          mappingTemplate: {
            index_patterns: ['eldonia-logs-*'],
            settings: {
              number_of_shards: 1,
              number_of_replicas: 0
            },
            mappings: {
              properties: {
                '@timestamp': { type: 'date' },
                level: { type: 'keyword' },
                service: { type: 'keyword' },
                component: { type: 'keyword' },
                operation: { type: 'keyword' },
                userId: { type: 'keyword' },
                requestId: { type: 'keyword' },
                message: { type: 'text' },
                metadata: { type: 'object', dynamic: true }
              }
            }
          }
        })
      ]
    });
  }

  // æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›
  log(level: string, message: string, metadata?: Partial<LogEntry>): void {
    const logEntry: LogEntry = {
      timestamp: new Date().toISOString(),
      level: level as LogEntry['level'],
      service: metadata?.service || this.logger.defaultMeta?.service || 'unknown',
      component: metadata?.component || 'unknown',
      operation: metadata?.operation || 'unknown',
      userId: metadata?.userId,
      sessionId: metadata?.sessionId,
      requestId: metadata?.requestId,
      ipAddress: metadata?.ipAddress,
      userAgent: metadata?.userAgent,
      message,
      metadata: metadata?.metadata,
      error: metadata?.error,
      performance: metadata?.performance
    };

    this.logger.log(level, message, logEntry);
  }

  // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
  error(message: string, error?: Error, metadata?: Partial<LogEntry>): void {
    this.log('error', message, {
      ...metadata,
      error: error ? {
        name: error.name,
        message: error.message,
        stack: error.stack,
        code: (error as any).code
      } : undefined
    });
  }

  // è­¦å‘Šãƒ­ã‚°
  warn(message: string, metadata?: Partial<LogEntry>): void {
    this.log('warn', message, metadata);
  }

  // æƒ…å ±ãƒ­ã‚°
  info(message: string, metadata?: Partial<LogEntry>): void {
    this.log('info', message, metadata);
  }

  // ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
  debug(message: string, metadata?: Partial<LogEntry>): void {
    this.log('debug', message, metadata);
  }

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°
  performance(operation: string, duration: number, metadata?: Partial<LogEntry>): void {
    this.log('info', `Performance: ${operation} completed in ${duration}ms`, {
      ...metadata,
      operation,
      performance: {
        duration,
        memoryUsage: process.memoryUsage().heapUsed,
        cpuUsage: process.cpuUsage().user
      }
    });
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°
  security(event: string, userId?: string, metadata?: Partial<LogEntry>): void {
    this.log('warn', `Security Event: ${event}`, {
      ...metadata,
      userId,
      component: 'security'
    });
  }

  // ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚°
  business(event: string, userId?: string, metadata?: Partial<LogEntry>): void {
    this.log('info', `Business Event: ${event}`, {
      ...metadata,
      userId,
      component: 'business'
    });
  }
}

// ãƒ­ã‚°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
export const logger = new Logger('eldonia-backend');
export const securityLogger = new Logger('eldonia-security');
export const businessLogger = new Logger('eldonia-business');
```

### 9.3.2 ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
```yaml
# fluentd/conf/fluent.conf
<source>
  @type tail
  path /var/log/eldonia/*.log
  pos_file /var/log/fluentd/eldonia.pos
  tag eldonia.*
  read_from_head true
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%LZ
  </parse>
</source>

<filter eldonia.**>
  @type record_transformer
  <record>
    environment "#{ENV['NODE_ENV'] || 'development'}"
    hostname "#{Socket.gethostname}"
  </record>
</filter>

<match eldonia.error>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix eldonia-error-logs
  <buffer>
    @type file
    path /var/log/fluentd/buffer/error
    flush_interval 5s
    chunk_limit_size 2M
    queue_limit_length 8
  </buffer>
</match>

<match eldonia.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix eldonia-logs
  <buffer>
    @type file
    path /var/log/fluentd/buffer/general
    flush_interval 10s
    chunk_limit_size 5M
    queue_limit_length 16
  </buffer>
</match>

# ãƒ­ã‚°ä¿æŒæœŸé–“è¨­å®š
<match eldonia.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix eldonia-logs
  index_name eldonia-logs-%Y.%m.%d
  <buffer>
    @type file
    path /var/log/fluentd/buffer/retention
    flush_interval 1h
    chunk_limit_size 10M
    queue_limit_length 32
  </buffer>
</match>
```

## 9.4 ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

### 9.4.1 Prometheus ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
```yaml
# prometheus/alerts.yml
groups:
  - name: eldonia-alerts
    rules:
      # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ©ãƒ¼ãƒˆ
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      - alert: LowThroughput
        expr: rate(http_requests_total[5m]) < 10
        for: 10m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "Low throughput detected"
          description: "Request rate is {{ $value }} requests per second"

      # ã‚¤ãƒ³ãƒ•ãƒ©ã‚¢ãƒ©ãƒ¼ãƒˆ
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}%"

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}%"

      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High disk usage detected"
          description: "Disk usage is {{ $value }}%"

      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ
      - alert: DatabaseConnectionHigh
        expr: pg_stat_database_numbackends > 80
        for: 2m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections"

      - alert: DatabaseSlowQueries
        expr: rate(pg_stat_activity_max_tx_duration{datname!=""}[5m]) > 30
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Slow database queries detected"
          description: "Average query duration is {{ $value }}s"

      # å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ
      - alert: AWSServiceDown
        expr: up{job="aws-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          service: aws
        annotations:
          summary: "AWS service is down"
          description: "AWS exporter is not responding"

      - alert: PaymentGatewayError
        expr: rate(payment_requests_total{status="error"}[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
          service: payment
        annotations:
          summary: "Payment gateway errors detected"
          description: "Payment error rate is {{ $value }} errors per second"

      # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆ
      - alert: HighFailedLogins
        expr: rate(auth_failed_logins_total[5m]) > 10
        for: 2m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High number of failed login attempts"
          description: "{{ $value }} failed logins per second"

      - alert: SuspiciousActivity
        expr: rate(security_events_total{type="suspicious"}[5m]) > 5
        for: 1m
        labels:
          severity: critical
          service: security
        annotations:
          summary: "Suspicious activity detected"
          description: "{{ $value }} suspicious events per second"
```

### 9.4.2 Alertmanagerè¨­å®š
```yaml
# alertmanager/alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR_SLACK_WEBHOOK'

route:
  group_by: ['alertname', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'slack-notifications'
  routes:
    - match:
        severity: critical
      receiver: 'pager-duty-critical'
      continue: true
    
    - match:
        severity: warning
      receiver: 'slack-notifications'
    
    - match:
        service: security
      receiver: 'security-team'
      continue: true

receivers:
  - name: 'slack-notifications'
    slack_configs:
      - channel: '#eldonia-alerts'
        title: '{{ template "slack.eldonia.title" . }}'
        text: '{{ template "slack.eldonia.text" . }}'
        actions:
          - type: button
            text: 'View in Grafana'
            url: '{{ template "slack.eldonia.grafana" . }}'
        send_resolved: true

  - name: 'pager-duty-critical'
    pagerduty_configs:
      - routing_key: YOUR_PAGERDUTY_KEY
        description: '{{ template "pagerduty.eldonia.description" . }}'
        severity: '{{ if eq .GroupLabels.severity "critical" }}critical{{ else }}warning{{ end }}'
        client: 'Eldonia Monitoring'
        client_url: '{{ template "pagerduty.eldonia.clientURL" . }}'

  - name: 'security-team'
    slack_configs:
      - channel: '#eldonia-security'
        title: '{{ template "slack.eldonia.security.title" . }}'
        text: '{{ template "slack.eldonia.security.text" . }}'
        send_resolved: true

templates:
  - '/etc/alertmanager/template/*.tmpl'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service']
```

---

## 9.5 éšœå®³å¯¾å¿œ

### 9.5.1 éšœå®³ãƒ¬ãƒ™ãƒ«å®šç¾©
```typescript
// backend/src/types/incident.ts
export enum IncidentSeverity {
  CRITICAL = 'critical',    // ã‚µãƒ¼ãƒ“ã‚¹å®Œå…¨åœæ­¢
  HIGH = 'high',           // ä¸»è¦æ©Ÿèƒ½åœæ­¢
  MEDIUM = 'medium',       // éƒ¨åˆ†æ©Ÿèƒ½åœæ­¢
  LOW = 'low',             // æ©Ÿèƒ½åŠ£åŒ–
  INFO = 'info'            // æƒ…å ±æä¾›
}

export enum IncidentStatus {
  OPEN = 'open',           // å¯¾å¿œä¸­
  INVESTIGATING = 'investigating', // èª¿æŸ»ä¸­
  RESOLVED = 'resolved',   // è§£æ±ºæ¸ˆã¿
  CLOSED = 'closed',       // å®Œäº†
  ESCALATED = 'escalated'  // ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
}

export interface Incident {
  id: string;
  title: string;
  description: string;
  severity: IncidentSeverity;
  status: IncidentStatus;
  service: string;
  component: string;
  detectedAt: Date;
  resolvedAt?: Date;
  assignedTo?: string;
  escalationLevel: number;
  impact: {
    users: number;
    revenue: number;
    reputation: string;
  };
  rootCause?: string;
  resolution?: string;
  lessonsLearned?: string;
  createdAt: Date;
  updatedAt: Date;
}

// éšœå®³å¯¾å¿œãƒ•ãƒ­ãƒ¼
export class IncidentResponse {
  private incident: Incident;
  private logger: any;

  constructor(incident: Incident) {
    this.incident = incident;
    this.logger = require('../utils/logger').logger;
  }

  // åˆæœŸå¯¾å¿œ
  async initialResponse(): Promise<void> {
    this.logger.info('Incident initial response started', {
      incidentId: this.incident.id,
      severity: this.incident.severity,
      service: this.incident.service
    });

    // 1. çŠ¶æ³ç¢ºèªãƒ»å½±éŸ¿ç¯„å›²èª¿æŸ»
    await this.assessImpact();
    
    // 2. åˆæœŸå¯¾å¿œãƒãƒ¼ãƒ ç·¨æˆ
    await this.assembleResponseTeam();
    
    // 3. ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®é€šçŸ¥
    await this.notifyStakeholders();
    
    // 4. ä¸€æ™‚çš„å›é¿ç­–ã®å®Ÿæ–½
    await this.implementWorkaround();
  }

  // è©³ç´°èª¿æŸ»
  async investigate(): Promise<void> {
    this.logger.info('Incident investigation started', {
      incidentId: this.incident.id
    });

    // 1. ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ
    await this.analyzeLogsAndMetrics();
    
    // 2. æ ¹æœ¬åŸå› ç‰¹å®š
    await this.identifyRootCause();
    
    // 3. å½±éŸ¿ç¯„å›²ã®è©³ç´°è©•ä¾¡
    await this.detailedImpactAssessment();
    
    // 4. å¾©æ—§è¨ˆç”»ç­–å®š
    await this.createRecoveryPlan();
  }

  // å¾©æ—§ä½œæ¥­
  async recover(): Promise<void> {
    this.logger.info('Incident recovery started', {
      incidentId: this.incident.id
    });

    // 1. å¾©æ—§è¨ˆç”»ã®å®Ÿè¡Œ
    await this.executeRecoveryPlan();
    
    // 2. æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    await this.testFunctionality();
    
    // 3. ç›£è¦–å¼·åŒ–
    await this.enhanceMonitoring();
    
    // 4. å¾©æ—§ç¢ºèª
    await this.verifyRecovery();
  }

  // äº‹å¾Œå¯¾å¿œ
  async postIncident(): Promise<void> {
    this.logger.info('Post-incident activities started', {
      incidentId: this.incident.id
    });

    // 1. äº‹å¾Œåˆ†æ
    await this.postIncidentAnalysis();
    
    // 2. æ”¹å–„ç­–ã®ç­–å®šãƒ»å®Ÿè¡Œ
    await this.implementImprovements();
    
    // 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
    await this.updateDocumentation();
    
    // 4. ãƒãƒ¼ãƒ æŒ¯ã‚Šè¿”ã‚Š
    await this.teamRetrospective();
  }

  private async assessImpact(): Promise<void> {
    // å½±éŸ¿ç¯„å›²ã®è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
    const impact = await this.calculateImpact();
    this.incident.impact = impact;
    
    this.logger.info('Impact assessment completed', {
      incidentId: this.incident.id,
      impact: this.incident.impact
    });
  }

  private async assembleResponseTeam(): Promise<void> {
    // å¯¾å¿œãƒãƒ¼ãƒ ç·¨æˆãƒ­ã‚¸ãƒƒã‚¯
    const team = await this.determineResponseTeam();
    
    this.logger.info('Response team assembled', {
      incidentId: this.incident.id,
      team: team
    });
  }

  private async notifyStakeholders(): Promise<void> {
    // ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼é€šçŸ¥ãƒ­ã‚¸ãƒƒã‚¯
    await this.sendNotifications();
    
    this.logger.info('Stakeholders notified', {
      incidentId: this.incident.id
    });
  }

  private async implementWorkaround(): Promise<void> {
    // ä¸€æ™‚çš„å›é¿ç­–ã®å®Ÿè£…
    await this.applyWorkaround();
    
    this.logger.info('Workaround implemented', {
      incidentId: this.incident.id
    });
  }

  private async analyzeLogsAndMetrics(): Promise<void> {
    // ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ
    const analysis = await this.performAnalysis();
    
    this.logger.info('Logs and metrics analyzed', {
      incidentId: this.incident.id,
      analysis: analysis
    });
  }

  private async identifyRootCause(): Promise<void> {
    // æ ¹æœ¬åŸå› ç‰¹å®š
    const rootCause = await this.findRootCause();
    this.incident.rootCause = rootCause;
    
    this.logger.info('Root cause identified', {
      incidentId: this.incident.id,
      rootCause: rootCause
    });
  }

  private async createRecoveryPlan(): Promise<void> {
    // å¾©æ—§è¨ˆç”»ç­–å®š
    const plan = await this.developRecoveryPlan();
    
    this.logger.info('Recovery plan created', {
      incidentId: this.incident.id,
      plan: plan
    });
  }

  private async executeRecoveryPlan(): Promise<void> {
    // å¾©æ—§è¨ˆç”»å®Ÿè¡Œ
    await this.implementRecoveryPlan();
    
    this.logger.info('Recovery plan executed', {
      incidentId: this.incident.id
    });
  }

  private async testFunctionality(): Promise<void> {
    // æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    const testResults = await this.runFunctionalityTests();
    
    this.logger.info('Functionality tests completed', {
      incidentId: this.incident.id,
      testResults: testResults
    });
  }

  private async verifyRecovery(): Promise<void> {
    // å¾©æ—§ç¢ºèª
    const recoveryStatus = await this.checkRecoveryStatus();
    
    if (recoveryStatus.success) {
      this.incident.status = IncidentStatus.RESOLVED;
      this.incident.resolvedAt = new Date();
      
      this.logger.info('Incident resolved', {
        incidentId: this.incident.id,
        resolutionTime: this.incident.resolvedAt
      });
    }
  }

  // ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã¯çœç•¥ï¼‰
  private async calculateImpact() { return { users: 0, revenue: 0, reputation: 'low' }; }
  private async determineResponseTeam() { return ['dev1', 'dev2']; }
  private async sendNotifications() { /* é€šçŸ¥ãƒ­ã‚¸ãƒƒã‚¯ */ }
  private async applyWorkaround() { /* å›é¿ç­–å®Ÿè£… */ }
  private async performAnalysis() { return {}; }
  private async findRootCause() { return 'Unknown'; }
  private async developRecoveryPlan() { return {}; }
  private async implementRecoveryPlan() { /* å¾©æ—§è¨ˆç”»å®Ÿè¡Œ */ }
  private async runFunctionalityTests() { return { success: true }; }
  private async checkRecoveryStatus() { return { success: true }; }
}
```

### 9.5.2 éšœå®³å¯¾å¿œæ‰‹é †æ›¸
```markdown
# éšœå®³å¯¾å¿œæ‰‹é †æ›¸

## 1. éšœå®³æ¤œçŸ¥æ™‚ã®å¯¾å¿œ

### 1.1 å³åº§ã®å¯¾å¿œ
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¢ºèªãƒ»çŠ¶æ³æŠŠæ¡
- [ ] å½±éŸ¿ç¯„å›²ã®åˆæœŸè©•ä¾¡
- [ ] å¯¾å¿œãƒãƒ¼ãƒ ã®å¬é›†
- [ ] ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®åˆæœŸå ±å‘Š

### 1.2 çŠ¶æ³ç¢ºèª
- [ ] ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª
- [ ] ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¢ºèª
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å½±éŸ¿ç¢ºèª
- [ ] ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®è©•ä¾¡

## 2. éšœå®³ãƒ¬ãƒ™ãƒ«åˆ¥å¯¾å¿œ

### 2.1 Criticalï¼ˆã‚µãƒ¼ãƒ“ã‚¹å®Œå…¨åœæ­¢ï¼‰
**å¯¾å¿œæ™‚é–“**: 15åˆ†ä»¥å†…
**å¯¾å¿œè€…**: å…¨ãƒãƒ¼ãƒ  + çµŒå–¶å±¤

- [ ] å…¨ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®å¬é›†
- [ ] çµŒå–¶å±¤ã¸ã®å³åº§ã®å ±å‘Š
- [ ] å¤–éƒ¨ãƒ™ãƒ³ãƒ€ãƒ¼ã¸ã®é€£çµ¡
- [ ] 24æ™‚é–“ä½“åˆ¶ã§ã®å¯¾å¿œé–‹å§‹

### 2.2 Highï¼ˆä¸»è¦æ©Ÿèƒ½åœæ­¢ï¼‰
**å¯¾å¿œæ™‚é–“**: 1æ™‚é–“ä»¥å†…
**å¯¾å¿œè€…**: é–‹ç™ºãƒãƒ¼ãƒ  + ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ 

- [ ] é–‹ç™ºãƒãƒ¼ãƒ ã®å¬é›†
- [ ] ã‚¤ãƒ³ãƒ•ãƒ©ãƒãƒ¼ãƒ ã®æ”¯æ´è¦è«‹
- [ ] ä¸€æ™‚çš„å›é¿ç­–ã®æ¤œè¨ãƒ»å®Ÿè£…
- [ ] å¾©æ—§ä½œæ¥­ã®é–‹å§‹

### 2.3 Mediumï¼ˆéƒ¨åˆ†æ©Ÿèƒ½åœæ­¢ï¼‰
**å¯¾å¿œæ™‚é–“**: 4æ™‚é–“ä»¥å†…
**å¯¾å¿œè€…**: é–‹ç™ºãƒãƒ¼ãƒ 

- [ ] é–‹ç™ºãƒãƒ¼ãƒ ã§ã®å¯¾å¿œé–‹å§‹
- [ ] å½±éŸ¿ç¯„å›²ã®è©³ç´°èª¿æŸ»
- [ ] å¾©æ—§è¨ˆç”»ã®ç­–å®š
- [ ] å¾©æ—§ä½œæ¥­ã®å®Ÿè¡Œ

## 3. å¾©æ—§ä½œæ¥­

### 3.1 ä¸€æ™‚çš„å›é¿ç­–
- [ ] æ©Ÿèƒ½ã®ç„¡åŠ¹åŒ–ãƒ»åˆ¶é™
- [ ] è² è·åˆ†æ•£ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
- [ ] ä»£æ›¿æ‰‹æ®µã®æä¾›
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ¡ˆå†…

### 3.2 æ ¹æœ¬çš„è§£æ±º
- [ ] æ ¹æœ¬åŸå› ã®ç‰¹å®š
- [ ] ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã®é–‹ç™º
- [ ] ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼
- [ ] æœ¬ç•ªç’°å¢ƒã¸ã®é©ç”¨

## 4. äº‹å¾Œå¯¾å¿œ

### 4.1 äº‹å¾Œåˆ†æ
- [ ] éšœå®³ã®è©³ç´°åˆ†æ
- [ ] å¯¾å¿œãƒ—ãƒ­ã‚»ã‚¹ã®è©•ä¾¡
- [ ] æ”¹å–„ç‚¹ã®ç‰¹å®š
- [ ] å†ç™ºé˜²æ­¢ç­–ã®ç­–å®š

### 4.2 æ”¹å–„ãƒ»äºˆé˜²
- [ ] ç›£è¦–ã®å¼·åŒ–
- [ ] è‡ªå‹•åŒ–ã®æ¨é€²
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›´æ–°
- [ ] ãƒãƒ¼ãƒ ç ”ä¿®ã®å®Ÿæ–½

## 5. å ±å‘Šãƒ»è¨˜éŒ²

### 5.1 å ±å‘Šæ›¸ã®ä½œæˆ
- [ ] éšœå®³ã®æ¦‚è¦
- [ ] å½±éŸ¿ç¯„å›²ãƒ»è¢«å®³
- [ ] å¯¾å¿œçµŒé
- [ ] æ ¹æœ¬åŸå› 
- [ ] å†ç™ºé˜²æ­¢ç­–
- [ ] æ•™è¨“ãƒ»æ”¹å–„ç‚¹

### 5.2 é–¢ä¿‚è€…ã¸ã®å ±å‘Š
- [ ] çµŒå–¶å±¤ã¸ã®å ±å‘Š
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®èª¬æ˜
- [ ] ãƒãƒ¼ãƒ å†…ã§ã®å…±æœ‰
- [ ] å¤–éƒ¨ã¸ã®å…¬è¡¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
```

## 9.6 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

### 9.6.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
```typescript
// backend/src/monitoring/performance.ts
import { performance } from 'perf_hooks';
import { logger } from '../utils/logger';

export interface PerformanceMetrics {
  timestamp: Date;
  operation: string;
  duration: number;
  memoryUsage: NodeJS.MemoryUsage;
  cpuUsage: NodeJS.CpuUsage;
  databaseQueries: number;
  cacheHits: number;
  cacheMisses: number;
  externalApiCalls: number;
  errors: number;
}

export class PerformanceMonitor {
  private metrics: PerformanceMetrics[] = [];
  private startTimes: Map<string, number> = new Map();

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šé–‹å§‹
  startTimer(operation: string): void {
    this.startTimes.set(operation, performance.now());
  }

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµ‚äº†
  endTimer(operation: string, metadata?: Partial<PerformanceMetrics>): void {
    const startTime = this.startTimes.get(operation);
    if (!startTime) return;

    const duration = performance.now() - startTime;
    const metrics: PerformanceMetrics = {
      timestamp: new Date(),
      operation,
      duration,
      memoryUsage: process.memoryUsage(),
      cpuUsage: process.cpuUsage(),
      databaseQueries: metadata?.databaseQueries || 0,
      cacheHits: metadata?.cacheHits || 0,
      cacheMisses: metadata?.cacheMisses || 0,
      externalApiCalls: metadata?.externalApiCalls || 0,
      errors: metadata?.errors || 0
    };

    this.metrics.push(metrics);
    this.startTimes.delete(operation);

    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°å‡ºåŠ›
    logger.performance(operation, duration, {
      operation,
      metadata: {
        memoryUsage: metrics.memoryUsage,
        cpuUsage: metrics.cpuUsage,
        databaseQueries: metrics.databaseQueries,
        cacheHits: metrics.cacheHits,
        cacheMisses: metrics.cacheMisses,
        externalApiCalls: metrics.externalApiCalls,
        errors: metrics.errors
      }
    });

    // ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ãƒã‚§ãƒƒã‚¯
    this.checkPerformanceAlerts(metrics);
  }

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
  private checkPerformanceAlerts(metrics: PerformanceMetrics): void {
    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚¢ãƒ©ãƒ¼ãƒˆ
    if (metrics.duration > 2000) { // 2ç§’ä»¥ä¸Š
      logger.warn('Performance alert: Slow operation detected', {
        operation: metrics.operation,
        duration: metrics.duration,
        threshold: 2000
      });
    }

    // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚¢ãƒ©ãƒ¼ãƒˆ
    const memoryUsagePercent = (metrics.memoryUsage.heapUsed / metrics.memoryUsage.heapTotal) * 100;
    if (memoryUsagePercent > 80) {
      logger.warn('Performance alert: High memory usage', {
        operation: metrics.operation,
        memoryUsagePercent,
        threshold: 80
      });
    }

    // ã‚¨ãƒ©ãƒ¼ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
    if (metrics.errors > 0) {
      logger.warn('Performance alert: Errors detected during operation', {
        operation: metrics.operation,
        errorCount: metrics.errors
      });
    }
  }

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  generateReport(): any {
    const totalOperations = this.metrics.length;
    if (totalOperations === 0) return null;

    const avgDuration = this.metrics.reduce((sum, m) => sum + m.duration, 0) / totalOperations;
    const maxDuration = Math.max(...this.metrics.map(m => m.duration));
    const minDuration = Math.min(...this.metrics.map(m => m.duration));

    const totalErrors = this.metrics.reduce((sum, m) => sum + m.errors, 0);
    const errorRate = (totalErrors / totalOperations) * 100;

    const totalDatabaseQueries = this.metrics.reduce((sum, m) => sum + m.databaseQueries, 0);
    const avgDatabaseQueries = totalDatabaseQueries / totalOperations;

    const totalCacheHits = this.metrics.reduce((sum, m) => sum + m.cacheHits, 0);
    const totalCacheMisses = this.metrics.reduce((sum, m) => sum + m.cacheMisses, 0);
    const cacheHitRate = totalCacheHits + totalCacheMisses > 0 
      ? (totalCacheHits / (totalCacheHits + totalCacheMisses)) * 100 
      : 0;

    return {
      summary: {
        totalOperations,
        avgDuration: Math.round(avgDuration * 100) / 100,
        maxDuration: Math.round(maxDuration * 100) / 100,
        minDuration: Math.round(minDuration * 100) / 100,
        errorRate: Math.round(errorRate * 100) / 100,
        avgDatabaseQueries: Math.round(avgDatabaseQueries * 100) / 100,
        cacheHitRate: Math.round(cacheHitRate * 100) / 100
      },
      operations: this.metrics.map(m => ({
        operation: m.operation,
        duration: m.duration,
        timestamp: m.timestamp,
        errors: m.errors
      }))
    };
  }

  // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ãƒªã‚¢
  clearMetrics(): void {
    this.metrics = [];
    this.startTimes.clear();
  }
}

// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const performanceMonitor = new PerformanceMonitor();

// ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã¨ã—ã¦ä½¿ç”¨
export const performanceMiddleware = (req: any, res: any, next: any) => {
  const operation = `${req.method} ${req.path}`;
  performanceMonitor.startTimer(operation);

  // ãƒ¬ã‚¹ãƒãƒ³ã‚¹çµ‚äº†æ™‚ã®å‡¦ç†
  res.on('finish', () => {
    performanceMonitor.endTimer(operation, {
      databaseQueries: req.databaseQueries || 0,
      cacheHits: req.cacheHits || 0,
      cacheMisses: req.cacheMisses || 0,
      externalApiCalls: req.externalApiCalls || 0,
      errors: res.statusCode >= 400 ? 1 : 0
    });
  });

  next();
};
```

## 9.7 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–

### 9.7.1 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆç›£è¦–
```typescript
// backend/src/monitoring/security.ts
import { logger } from '../utils/logger';
import { securityLogger } from '../utils/logger';

export interface SecurityEvent {
  id: string;
  timestamp: Date;
  type: SecurityEventType;
  severity: SecurityEventSeverity;
  userId?: string;
  ipAddress?: string;
  userAgent?: string;
  sessionId?: string;
  details: any;
  source: string;
  status: SecurityEventStatus;
}

export enum SecurityEventType {
  FAILED_LOGIN = 'failed_login',
  SUSPICIOUS_ACTIVITY = 'suspicious_activity',
  UNAUTHORIZED_ACCESS = 'unauthorized_access',
  DATA_ACCESS = 'data_access',
  CONFIGURATION_CHANGE = 'configuration_change',
  MALWARE_DETECTED = 'malware_detected',
  BRUTE_FORCE_ATTEMPT = 'brute_force_attempt',
  SQL_INJECTION_ATTEMPT = 'sql_injection_attempt',
  XSS_ATTEMPT = 'xss_attempt',
  CSRF_ATTEMPT = 'csrf_attempt'
}

export enum SecurityEventSeverity {
  LOW = 'low',
  MEDIUM = 'medium',
  HIGH = 'high',
  CRITICAL = 'critical'
}

export enum SecurityEventStatus {
  OPEN = 'open',
  INVESTIGATING = 'investigating',
  RESOLVED = 'resolved',
  FALSE_POSITIVE = 'false_positive'
}

export class SecurityMonitor {
  private events: SecurityEvent[] = [];
  private alertThresholds: Map<SecurityEventType, number> = new Map();
  private timeWindows: Map<SecurityEventType, number> = new Map();

  constructor() {
    this.initializeThresholds();
  }

  private initializeThresholds(): void {
    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã®é–¾å€¤è¨­å®š
    this.alertThresholds.set(SecurityEventType.FAILED_LOGIN, 5);
    this.alertThresholds.set(SecurityEventType.SUSPICIOUS_ACTIVITY, 3);
    this.alertThresholds.set(SecurityEventType.UNAUTHORIZED_ACCESS, 1);
    this.alertThresholds.set(SecurityEventType.BRUTE_FORCE_ATTEMPT, 10);
    this.alertThresholds.set(SecurityEventType.SQL_INJECTION_ATTEMPT, 1);
    this.alertThresholds.set(SecurityEventType.XSS_ATTEMPT, 1);
    this.alertThresholds.set(SecurityEventType.CSRF_ATTEMPT, 1);

    // æ™‚é–“çª“è¨­å®šï¼ˆåˆ†ï¼‰
    this.timeWindows.set(SecurityEventType.FAILED_LOGIN, 5);
    this.timeWindows.set(SecurityEventType.SUSPICIOUS_ACTIVITY, 10);
    this.timeWindows.set(SecurityEventType.UNAUTHORIZED_ACCESS, 1);
    this.alertThresholds.set(SecurityEventType.BRUTE_FORCE_ATTEMPT, 5);
    this.alertThresholds.set(SecurityEventType.SQL_INJECTION_ATTEMPT, 1);
    this.alertThresholds.set(SecurityEventType.XSS_ATTEMPT, 1);
    this.alertThresholds.set(SecurityEventType.CSRF_ATTEMPT, 1);
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
  recordEvent(
    type: SecurityEventType,
    severity: SecurityEventSeverity,
    details: any,
    source: string,
    userId?: string,
    ipAddress?: string,
    userAgent?: string,
    sessionId?: string
  ): void {
    const event: SecurityEvent = {
      id: this.generateEventId(),
      timestamp: new Date(),
      type,
      severity,
      userId,
      ipAddress,
      userAgent,
      sessionId,
      details,
      source,
      status: SecurityEventStatus.OPEN
    };

    this.events.push(event);

    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°å‡ºåŠ›
    securityLogger.security(`Security event: ${type}`, userId, {
      eventType: type,
      severity,
      ipAddress,
      userAgent,
      sessionId,
      details,
      source
    });

    // ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    this.checkSecurityAlerts(type, event);
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
  private checkSecurityAlerts(type: SecurityEventType, event: SecurityEvent): void {
    const threshold = this.alertThresholds.get(type);
    const timeWindow = this.timeWindows.get(type);

    if (!threshold || !timeWindow) return;

    const recentEvents = this.events.filter(e => 
      e.type === type && 
      e.timestamp.getTime() > Date.now() - (timeWindow * 60 * 1000)
    );

    if (recentEvents.length >= threshold) {
      this.triggerSecurityAlert(type, recentEvents, threshold, timeWindow);
    }
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç«
  private triggerSecurityAlert(
    type: SecurityEventType,
    events: SecurityEvent[],
    threshold: number,
    timeWindow: number
  ): void {
    const alertMessage = `Security alert: ${type} threshold exceeded`;
    const alertDetails = {
      eventType: type,
      eventCount: events.length,
      threshold,
      timeWindow,
      events: events.map(e => ({
        id: e.id,
        timestamp: e.timestamp,
        userId: e.userId,
        ipAddress: e.ipAddress,
        details: e.details
      }))
    };

    // ã‚¢ãƒ©ãƒ¼ãƒˆãƒ­ã‚°å‡ºåŠ›
    securityLogger.error(alertMessage, undefined, {
      eventType: 'security_alert',
      component: 'security_monitor',
      metadata: alertDetails
    });

    // å¤–éƒ¨ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®é€šçŸ¥
    this.sendSecurityAlert(alertMessage, alertDetails);
  }

  // å¤–éƒ¨ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¸ã®é€šçŸ¥
  private async sendSecurityAlert(message: string, details: any): Promise<void> {
    try {
      // Slacké€šçŸ¥
      await this.sendSlackAlert(message, details);
      
      // PagerDutyé€šçŸ¥ï¼ˆé‡å¤§ãªå ´åˆï¼‰
      if (this.hasCriticalEvents(details.events)) {
        await this.sendPagerDutyAlert(message, details);
      }
      
      // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ ã¸ã®é€šçŸ¥
      await this.notifySecurityTeam(message, details);
    } catch (error) {
      logger.error('Failed to send security alert', error);
    }
  }

  // é‡å¤§ã‚¤ãƒ™ãƒ³ãƒˆã®åˆ¤å®š
  private hasCriticalEvents(events: any[]): boolean {
    return events.some(e => e.severity === SecurityEventSeverity.CRITICAL);
  }

  // Slacké€šçŸ¥
  private async sendSlackAlert(message: string, details: any): Promise<void> {
    // Slacké€šçŸ¥ã®å®Ÿè£…
    console.log('Slack alert sent:', message, details);
  }

  // PagerDutyé€šçŸ¥
  private async sendPagerDutyAlert(message: string, details: any): Promise<void> {
    // PagerDutyé€šçŸ¥ã®å®Ÿè£…
    console.log('PagerDuty alert sent:', message, details);
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ é€šçŸ¥
  private async notifySecurityTeam(message: string, details: any): Promise<void> {
    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ é€šçŸ¥ã®å®Ÿè£…
    console.log('Security team notified:', message, details);
  }

  // ã‚¤ãƒ™ãƒ³ãƒˆIDç”Ÿæˆ
  private generateEventId(): string {
    return `sec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  generateSecurityReport(): any {
    const totalEvents = this.events.length;
    if (totalEvents === 0) return null;

    const eventsByType = this.groupEventsByType();
    const eventsBySeverity = this.groupEventsBySeverity();
    const eventsByStatus = this.groupEventsByStatus();

    return {
      summary: {
        totalEvents,
        eventsByType,
        eventsBySeverity,
        eventsByStatus
      },
      recentEvents: this.events
        .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime())
        .slice(0, 100)
    };
  }

  private groupEventsByType(): Record<string, number> {
    return this.events.reduce((acc, event) => {
      acc[event.type] = (acc[event.type] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
  }

  private groupEventsBySeverity(): Record<string, number> {
    return this.events.reduce((acc, event) => {
      acc[event.severity] = (acc[event.severity] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
  }

  private groupEventsByStatus(): Record<string, number> {
    return this.events.reduce((acc, event) => {
      acc[event.status] = (acc[event.status] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
  }
}

// ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const securityMonitor = new SecurityMonitor();
```

## 9.8 é‹ç”¨è‡ªå‹•åŒ–

### 9.8.1 è‡ªå‹•å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# auto-recovery.sh - è‡ªå‹•å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

# è¨­å®š
SERVICE_NAME="eldonia-backend"
HEALTH_CHECK_URL="http://localhost:3001/health"
MAX_RESTART_ATTEMPTS=3
RESTART_DELAY=30
LOG_FILE="/var/log/eldonia/auto-recovery.log"

# ãƒ­ã‚°é–¢æ•°
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
check_health() {
    local response
    response=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_CHECK_URL" 2>/dev/null || echo "000")
    
    if [ "$response" = "200" ]; then
        return 0
    else
        return 1
    fi
}

# ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
restart_service() {
    log "Restarting $SERVICE_NAME..."
    
    if systemctl is-active --quiet "$SERVICE_NAME"; then
        systemctl restart "$SERVICE_NAME"
        log "Service restarted successfully"
    else
        systemctl start "$SERVICE_NAME"
        log "Service started successfully"
    fi
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    log "Auto-recovery script started"
    
    local attempt=1
    
    while [ $attempt -le $MAX_RESTART_ATTEMPTS ]; do
        log "Health check attempt $attempt/$MAX_RESTART_ATTEMPTS"
        
        if check_health; then
            log "Service is healthy. Exiting."
            exit 0
        else
            log "Service is unhealthy. Attempting restart..."
            restart_service
            
            log "Waiting $RESTART_DELAY seconds for service to stabilize..."
            sleep $RESTART_DELAY
            
            if check_health; then
                log "Service recovered after restart. Exiting."
                exit 0
            else
                log "Service still unhealthy after restart."
                attempt=$((attempt + 1))
            fi
        fi
    done
    
    log "Maximum restart attempts reached. Service recovery failed."
    log "Sending critical alert to operations team."
    
    # é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡
    send_critical_alert
    
    exit 1
}

# é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
send_critical_alert() {
    # Slacké€šçŸ¥
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"ğŸš¨ CRITICAL: $SERVICE_NAME auto-recovery failed after $MAX_RESTART_ATTEMPTS attempts. Manual intervention required.\"}" \
        "$SLACK_WEBHOOK_URL" 2>/dev/null || true
    
    # PagerDutyé€šçŸ¥
    curl -X POST -H 'Content-type: application/json' \
        -H "Authorization: Token token=$PAGERDUTY_API_KEY" \
        --data "{\"incident\":{\"type\":\"incident\",\"title\":\"$SERVICE_NAME Auto-Recovery Failed\",\"service\":{\"id\":\"$PAGERDUTY_SERVICE_ID\",\"type\":\"service_reference\"},\"urgency\":\"high\"}}" \
        "https://api.pagerduty.com/incidents" 2>/dev/null || true
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"
```

---

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³**: 10. é–‹ç™ºãƒ»é‹ç”¨ãƒ—ãƒ­ã‚»ã‚¹
